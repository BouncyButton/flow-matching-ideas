{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9148945,"sourceType":"datasetVersion","datasetId":5526342}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pickle\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\n# Paths to image folders (adjust if needed)\nLOW_ENERGY_DIR = '/kaggle/input/pkg-cdd-cesm/PKG - CDD-CESM/CDD-CESM/Low energy images of CDD-CESM'\nSUBTRACTED_DIR = '/kaggle/input/pkg-cdd-cesm/PKG - CDD-CESM/CDD-CESM/Subtracted images of CDD-CESM'\nOUTPUT_PATH = '/kaggle/working/cdd_cesm_dataset.pkl'\n\n# Image processing parameters\nCROP_SIZE = (2048, 2048)    # Center crop to this size first\nDOWNSCALE_SIZE = (256, 256)  # Final output size\n\ndef center_crop_and_downscale(pil_img):\n    \"\"\"Center crops and downscales an image using LANCZOS resampling\"\"\"\n    # Center crop\n    width, height = pil_img.size\n    left = (width - CROP_SIZE[0])//2\n    top = (height - CROP_SIZE[1])//2\n    right = left + CROP_SIZE[0]\n    bottom = top + CROP_SIZE[1]\n    cropped = pil_img.crop((left, top, right, bottom))\n    \n    # Downscale\n    return cropped.resize(DOWNSCALE_SIZE, Image.Resampling.LANCZOS)\n\ndef pairing_key(filename):\n    \"\"\"Extracts (patient, laterality, view) from filenames like 'P100_L_DM_CC.jpg'\"\"\"\n    parts = filename.split('_')\n    return (parts[0], parts[1], parts[3].split('.')[0])  # (P100, L, CC)\n\n# List and pair files\nle_files = [f for f in os.listdir(LOW_ENERGY_DIR) if f.lower().endswith('.jpg')]\nsub_files = [f for f in os.listdir(SUBTRACTED_DIR) if f.lower().endswith('.jpg')]\n\nle_dict = {pairing_key(f): f for f in le_files}\nsub_dict = {pairing_key(f): f for f in sub_files}\npairs = [(le_dict[k], sub_dict[k], k) for k in le_dict if k in sub_dict]\n\nprint(f\"Successfully paired {len(pairs)} images\")\n\n# Process and save dataset\nsamples = []\nfor le_fname, sub_fname, key in tqdm(pairs, desc=\"Processing images\"):\n    # Load and preprocess\n    le_img = center_crop_and_downscale(Image.open(os.path.join(LOW_ENERGY_DIR, le_fname)).convert('L'))\n    sub_img = center_crop_and_downscale(Image.open(os.path.join(SUBTRACTED_DIR, sub_fname)).convert('L'))\n    \n    # Convert to normalized tensors\n    le_arr = np.array(le_img, dtype=np.float32)[np.newaxis, ...] / 255.0  # [1, H, W]\n    sub_arr = np.array(sub_img, dtype=np.float32)[np.newaxis, ...] / 255.0\n    \n    samples.append({\n        'image': le_arr,\n        'mask': sub_arr,\n        'class': 0,  # Update with actual labels if available\n        'metadata': {\n            'patient': key[0],\n            'laterality': key[1],\n            'view': key[2],\n            'filenames': (le_fname, sub_fname)\n        }\n    })\n\n# Split and save\ntrain, test = train_test_split(samples, test_size=0.2, random_state=42)\nvalid, test = train_test_split(test, test_size=0.5, random_state=42)\n\nwith open(OUTPUT_PATH, 'wb') as f:\n    pickle.dump({'train': train, 'valid': valid, 'test': test}, f)\n\nprint(f\"Dataset saved to {OUTPUT_PATH}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:58:36.383050Z","iopub.execute_input":"2025-04-18T14:58:36.383526Z","iopub.status.idle":"2025-04-18T15:01:32.125132Z","shell.execute_reply.started":"2025-04-18T14:58:36.383465Z","shell.execute_reply":"2025-04-18T15:01:32.123671Z"}},"outputs":[{"name":"stdout","text":"Successfully paired 1002 images\n","output_type":"stream"},{"name":"stderr","text":"Processing images: 100%|██████████| 1002/1002 [02:53<00:00,  5.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dataset saved to /kaggle/working/cdd_cesm_dataset.pkl\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!rm cdd_cesm_dataset.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:56:47.089666Z","iopub.execute_input":"2025-04-18T14:56:47.090067Z","iopub.status.idle":"2025-04-18T14:56:48.652456Z","shell.execute_reply.started":"2025-04-18T14:56:47.090038Z","shell.execute_reply":"2025-04-18T14:56:48.650725Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}